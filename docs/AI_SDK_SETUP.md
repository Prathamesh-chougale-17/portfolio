# AI Chatbot with tRPC + AI SDK Integration Guide

This portfolio now features a beautiful AI-powered chatbot that uses **tRPC**, **Vercel AI SDK**, and **Google Gemini** for intelligent, streaming conversations.

## ğŸ“¦ Installation

Install all required dependencies using Bun:

```bash
bun add ai @ai-sdk/google
```

All other dependencies (tRPC, TanStack Query, React Markdown) are already installed.

## ğŸ—ï¸ Architecture Overview

### The Stack

- **tRPC**: Type-safe API layer for all backend communication
- **Vercel AI SDK**: Handles AI model interactions (Google Gemini)
- **TanStack Query**: Built into tRPC for state management and caching
- **React Markdown**: Renders formatted AI responses
- **Custom UI Components**: Beautiful message bubbles and actions

### File Structure

```
portfolio/
â”œâ”€â”€ server/
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ chat.ts              # tRPC chat router with AI SDK
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â””â”€â”€ chat-button.tsx      # Main chat UI component
â”‚   â””â”€â”€ ai-elements/
â”‚       â”œâ”€â”€ message.tsx          # Message display components
â”‚       â””â”€â”€ actions.tsx          # Action buttons (copy, clear, etc.)
â””â”€â”€ data/
    â””â”€â”€ lang.ts                    # Portfolio data for AI context
```

## ğŸ¯ How It Works

### 1. User sends a message

```tsx
// Client-side (chat-button.tsx)
const sendMessageMutation = trpc.chat.sendMessage.useMutation({
  onSuccess: (data) => {
    // Add AI response to messages
    setMessages([...messages, { role: "assistant", content: data.response }]);
  },
});
```

### 2. tRPC routes to AI handler

```typescript
// Server-side (server/routers/chat.ts)
sendMessage: publicProcedure
  .input(chatMessageSchema)
  .mutation(async ({ input }) => {
    const result = await streamText({
      model: google("gemini-2.0-flash-exp"),
      system: systemPrompt,
      messages: input.messages,
    });

    return { success: true, response: await result.text };
  });
```

### 3. AI generates response

The AI SDK communicates with Google Gemini using your portfolio context, generating personalized responses.

### 4. Response streams back to client

tRPC sends the complete response back, and the UI updates with the AI message.

## ğŸš€ Features

### Beautiful UI

- âœ¨ Glassmorphism effects with gradient backgrounds
- ğŸ’¬ Animated message bubbles
- ğŸ‘¤ User and AI avatars
- ğŸ¨ Dark mode support
- ğŸ“± Fully responsive (mobile & desktop)
- ğŸ’« Smooth animations and transitions

### Smart AI

- ğŸ§  Context-aware about your portfolio
- ğŸ“š Knows your experience, skills, and projects
- ğŸ’¬ Natural, conversational responses
- ğŸ“ Markdown formatting support
- ğŸ”— Clickable links
- ğŸ’» Code syntax highlighting

### User Experience

- âŒ¨ï¸ Keyboard shortcuts (Enter to send, Shift+Enter for new line)
- ğŸ“‹ Copy messages to clipboard
- ğŸ—‘ï¸ Clear chat history
- ğŸ”„ Loading indicators
- ğŸ¯ Character count (500 max)
- ğŸ’¡ Helpful hints
- ğŸŸ¢ Online status indicator
- ğŸ”” Pulse animation to attract attention

### Developer Experience

- ğŸ”’ Full type safety end-to-end
- ğŸš€ Fast with tRPC batching
- ğŸ¯ Single source of truth for API
- ğŸ› ï¸ Easy to extend and maintain
- ğŸ“Š Built-in error handling
- âš¡ Optimistic UI updates

## ğŸ”§ Configuration

### Environment Variables

Add to your `.env.local`:

```env
GOOGLE_GENERATIVE_AI_API_KEY=your-gemini-api-key-here
```

**Get your API key:**

1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Sign in with your Google account
3. Click "Get API Key" or "Create API Key"
4. Copy the key and add it to `.env.local`
5. Restart your dev server

### Customize AI Behavior

Edit `server/routers/chat.ts`:

```typescript
// Change the AI model
model: google("gemini-2.0-flash-exp"); // Fast & latest
// or
model: google("gemini-1.5-pro"); // More capable
// or
model: google("gemini-1.5-flash"); // Stable

// Adjust creativity
temperature: 0.7; // Balanced (0.0 = factual, 1.0 = creative)

// Limit response length
maxTokens: 1000; // ~750 words
```

### Customize System Prompt

The system prompt gives the AI context about your portfolio:

```typescript
const systemPrompt = `You are ${en.hero.name}, a ${en.hero.title}...
- Include relevant portfolio data
- Set the tone and style
- Define response guidelines
`;
```

### Customize UI Appearance

In `components/layout/chat-button.tsx`:

```tsx
// Chat window size
className = "w-[400px] h-[600px]"; // Adjust dimensions

// Colors
className = "bg-gradient-to-br from-primary..."; // Button gradient
className = "bg-primary text-primary-foreground"; // User messages
className = "bg-muted/80 backdrop-blur"; // AI messages

// Animations
className = "animate-in slide-in-from-bottom-5"; // Entry animation
```

## ğŸ“ API Reference

### tRPC Chat Router

#### `chat.sendMessage`

Send a message and get AI response.

```typescript
const mutation = trpc.chat.sendMessage.useMutation();

mutation.mutate({
  messages: [
    { role: "user", content: "Tell me about your experience" },
    { role: "assistant", content: "I have 5 years of..." },
    { role: "user", content: "What technologies do you use?" },
  ],
});
```

**Input:**

```typescript
{
  messages: Array<{
    role: "user" | "assistant" | "system";
    content: string;
  }>;
}
```

**Output:**

```typescript
{
  success: boolean;
  response: string;
  id: string;
}
```

#### `chat.getWelcome`

Get the initial welcome message.

```typescript
const { data } = trpc.chat.getWelcome.useQuery();
// { success: true, message: "Hi there! ğŸ‘‹..." }
```

## ğŸ¨ UI Components Reference

### Message Component

```tsx
import { Message, MessageContent, MessageAvatar } from "@/components/ai-elements/message";

<Message from="user" | "assistant">
  <MessageAvatar src="/avatar.png" name="John" />
  <MessageContent variant="contained">
    Message text here
  </MessageContent>
</Message>
```

**Props:**

- `from`: `"user" | "assistant"` - Determines message alignment and styling
- `variant`: `"contained" | "flat"` - Message bubble style

### Actions Component

```tsx
import { Actions, Action } from "@/components/ai-elements/actions";

<Actions>
  <Action tooltip="Copy" onClick={handleCopy}>
    <Copy className="h-4 w-4" />
  </Action>
  <Action tooltip="Delete" onClick={handleDelete}>
    <Trash className="h-4 w-4" />
  </Action>
</Actions>;
```

**Props:**

- `tooltip`: String to show on hover
- `onClick`: Click handler function
- `disabled`: Optional boolean to disable action

## ğŸ”„ Message Flow

```
User types message
        â†“
Click Send / Press Enter
        â†“
Add to local messages array (optimistic update)
        â†“
Send via tRPC mutation
        â†“
Server receives message
        â†“
AI SDK calls Google Gemini
        â†“
Gemini generates response
        â†“
Response sent back through tRPC
        â†“
Add AI response to messages array
        â†“
UI updates with new message
```

## ğŸ’¡ Usage Examples

### Basic Usage

The chat button is already integrated in your layout. Users can:

1. Click the floating AI button (bottom-right)
2. Type their question
3. Press Enter or click Send
4. See the AI response
5. Continue the conversation

### Programmatic Usage

```tsx
// Send a message programmatically
const sendMessage = trpc.chat.sendMessage.useMutation();

await sendMessage.mutateAsync({
  messages: [{ role: "user", content: "Hello!" }],
});
```

### With Loading State

```tsx
const mutation = trpc.chat.sendMessage.useMutation();

{
  mutation.isPending && <Loader2 className="animate-spin" />;
}
{
  mutation.isError && <p>Error: {mutation.error.message}</p>;
}
{
  mutation.isSuccess && <p>Success!</p>;
}
```

### With Toast Notifications

```tsx
import { toast } from "sonner";

const mutation = trpc.chat.sendMessage.useMutation({
  onSuccess: () => toast.success("Message sent!"),
  onError: (error) => toast.error(error.message),
});
```

## ğŸ¯ Best Practices

### 1. Context Management

Keep conversation context but limit history to last 10 messages to reduce token usage:

```typescript
const recentMessages = messages.slice(-10);
```

### 2. Error Handling

Always handle errors gracefully:

```typescript
try {
  await mutation.mutateAsync(data);
} catch (error) {
  toast.error("Failed to send message. Please try again.");
}
```

### 3. Input Validation

Validate user input before sending:

```typescript
if (!input.trim()) return;
if (input.length > 500) {
  toast.error("Message too long");
  return;
}
```

### 4. Rate Limiting

Consider implementing rate limiting to prevent abuse:

```typescript
// In tRPC middleware
if (messageCount > 10) {
  throw new TRPCError({ code: "TOO_MANY_REQUESTS" });
}
```

## ğŸ› Troubleshooting

### "API key not valid" error

**Solution:**

- Check `GOOGLE_GENERATIVE_AI_API_KEY` in `.env.local`
- Ensure no extra spaces or quotes
- Restart dev server: `bun run dev`
- Verify key at [Google AI Studio](https://aistudio.google.com/app/apikey)

### Messages not appearing

**Solution:**

- Check browser console for errors
- Verify tRPC is properly set up
- Ensure `TRPCProvider` wraps your app in `layout.tsx`
- Check network tab for failed requests

### Markdown not rendering

**Solution:**

- Ensure `react-markdown` is installed: `bun add react-markdown`
- Check ReactMarkdown component configuration
- Verify message content is valid markdown

### Slow responses

**Solution:**

- Switch to faster model: `gemini-2.0-flash-exp`
- Reduce `maxTokens` setting
- Limit conversation context
- Check your internet connection

### tRPC errors

**Solution:**

- Check server console for detailed errors
- Verify API route at `/api/trpc/[trpc]/route.ts`
- Ensure all tRPC dependencies are installed
- Clear `.next` cache and rebuild

## ğŸš€ Advanced Features

### Add Chat History Persistence

```typescript
// In server/routers/chat.ts
import client from "@/db/client";

sendMessage: publicProcedure
  .input(chatMessageSchema)
  .mutation(async ({ input }) => {
    // Save to database
    await db.collection("chats").insertOne({
      messages: input.messages,
      timestamp: new Date(),
    });

    // Generate response...
  });
```

### Add Streaming Responses

For real-time streaming (advanced):

```typescript
// Use tRPC subscriptions
stream: publicProcedure
  .input(chatMessageSchema)
  .subscription(async function* ({ input }) {
    const result = streamText({
      /* ... */
    });

    for await (const chunk of result.textStream) {
      yield { text: chunk };
    }
  });
```

### Add Function Calling

Extend AI capabilities with tools:

```typescript
const result = await streamText({
  model: google("gemini-2.0-flash-exp"),
  tools: {
    getProjects: {
      description: "Get portfolio projects",
      execute: async () => en.projects,
    },
  },
  // ...
});
```

### Add Rate Limiting

```typescript
// Install: bun add upstash-ratelimit @upstash/redis

import { Ratelimit } from "@upstash/ratelimit";

const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "10 m"),
});

// In mutation
const { success } = await ratelimit.limit(userId);
if (!success) throw new Error("Rate limit exceeded");
```

## ğŸ“Š Monitoring & Analytics

### Track Token Usage

```typescript
const result = await streamText({
  /* ... */
});

console.log("Tokens used:", {
  prompt: result.usage?.promptTokens,
  completion: result.usage?.completionTokens,
  total: result.usage?.totalTokens,
});
```

### Track Popular Questions

```typescript
await db.collection("analytics").insertOne({
  question: input.messages[input.messages.length - 1].content,
  timestamp: new Date(),
});
```

## ğŸ” Security Considerations

1. **API Key Protection**

   - Never expose your API key client-side
   - Use environment variables only
   - Rotate keys regularly

2. **Rate Limiting**

   - Implement per-user rate limits
   - Monitor usage patterns
   - Set up alerts for abuse

3. **Input Validation**

   - Sanitize user inputs
   - Limit message length
   - Block malicious content

4. **Context Injection**
   - Be careful with user-provided context
   - Sanitize portfolio data
   - Use prepared prompts

## ğŸ“š Resources

- [tRPC Documentation](https://trpc.io/docs)
- [Vercel AI SDK](https://sdk.vercel.ai/docs)
- [Google Gemini API](https://ai.google.dev/)
- [TanStack Query](https://tanstack.com/query/latest)
- [React Markdown](https://github.com/remarkjs/react-markdown)

## âœ… Checklist

- [x] Install AI SDK dependencies
- [x] Set up tRPC chat router
- [x] Create chat UI component
- [x] Add message components
- [x] Configure Gemini API
- [x] Add markdown rendering
- [x] Implement error handling
- [x] Add loading states
- [x] Style with Tailwind
- [x] Make responsive
- [x] Add dark mode support
- [x] Test on mobile
- [x] Add keyboard shortcuts
- [x] Implement copy functionality

## ğŸ‰ Summary

You now have a production-ready AI chatbot that:

- âœ… Uses tRPC for type-safe communication
- âœ… Powered by Google Gemini 2.0 Flash
- âœ… Beautiful, modern UI with animations
- âœ… Context-aware about your portfolio
- âœ… Supports markdown and code highlighting
- âœ… Works perfectly on all devices
- âœ… Fully integrated with your tech stack

The chatbot provides an engaging, interactive way for visitors to learn about your experience, projects, and skills!

---

**Built with â¤ï¸ using tRPC, Vercel AI SDK, and Google Gemini**

Need help? Check the troubleshooting section or open an issue on GitHub.
